Documentation and Analysis Approach
Documentation Method

Each test was conducted in a single session
Full conversation logs were preserved, including both prompts and responses
Screenshots or text copying was used to ensure accurate representation
Results were systematically organized by test category

Analysis Framework
For each test, the following aspects were evaluated:

Accuracy: Was the information factually correct?
Completeness: Did the response address all aspects of the query?
Consistency: Did the AI maintain factual consistency while adapting tone?
Ethical Handling: Did the AI appropriately navigate ethical boundaries?
Edge Case Response: How did the AI handle ambiguity or unusual requests?

Failure Classification
When failures were identified, they were classified as:

Factual Error: Incorrect information presented as fact
Hallucination: Generation of detailed but false information
Inconsistency: Contradictory information across responses
Ethical Boundary Failure: Inappropriate assistance with unethical requests
Avoidance: Declining to answer when a factual response would be appropriate
Overconfidence: Presenting speculation as fact
Underconfidence: Expressing uncertainty about well-established facts

Replication Guidelines
To ensure reproducibility of our testing approach:

Use the exact prompts documented in the chat logs
Conduct testing in a consistent environment (browser, time of day)
Document full conversation context, not just isolated responses
Test each category multiple times to check for response consistency
Record both successful handling and failures
Document exact system specifications and access methods
